{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcripts.json\", \"r\") as file:\n",
    "\tdata = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd84b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fde2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19489a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Analyze fields present in all data\n",
    "total_records = len(data)\n",
    "field_counts = Counter()\n",
    "all_keys = set()\n",
    "\n",
    "for entry in data:\n",
    "    keys = entry.keys()\n",
    "    field_counts.update(keys)\n",
    "    all_keys.update(keys)\n",
    "\n",
    "present_in_all = [key for key, count in field_counts.items() if count == total_records]\n",
    "missing_in_some = [key for key in all_keys if key not in present_in_all]\n",
    "\n",
    "print(f\"Total records: {total_records}\")\n",
    "print(f\"Fields present in all records: {present_in_all}\")\n",
    "print(f\"Fields missing in some records: {missing_in_some}\")\n",
    "\n",
    "# 2. Analyze conversation lengths\n",
    "# Assuming 'conversation' is the key for the dialogue list\n",
    "conversation_lengths = []\n",
    "for entry in data:\n",
    "    if 'conversation' in entry:\n",
    "        conversation_lengths.append(len(entry['conversation']))\n",
    "\n",
    "# Basic statistics\n",
    "if conversation_lengths:\n",
    "    avg_len = sum(conversation_lengths) / len(conversation_lengths)\n",
    "    max_len = max(conversation_lengths)\n",
    "    min_len = min(conversation_lengths)\n",
    "    \n",
    "    print(f\"\\nConversation Length Statistics (number of turns):\")\n",
    "    print(f\"Average Length: {avg_len:.2f}\")\n",
    "    print(f\"Max Length: {max_len}\")\n",
    "    print(f\"Min Length: {min_len}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(conversation_lengths, bins=30, edgecolor='black')\n",
    "    plt.title('Distribution of Conversation Lengths')\n",
    "    plt.xlabel('Number of Turns')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n'conversation' field not found or empty in the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda0832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"\\n-------Sample conversation {i+1}--------\")\n",
    "    print(f'domain: {data[i].get(\"domain\", \"N/A\")}')\n",
    "    print(f'intent: {data[i].get(\"intent\", \"N/A\")}')\n",
    "    print(f'reason_for_call: {data[i].get(\"reason_for_call\", \"N/A\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f24315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency distribution for 'domain'\n",
    "domain_counts = pd.Series([entry.get('domain', 'N/A') for entry in data]).value_counts()\n",
    "print(\"Domain Frequency Distribution:\")\n",
    "print(domain_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "domain_counts.plot(kind='bar')\n",
    "plt.title('Frequency Distribution of Domain')\n",
    "plt.xlabel('Domain')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Frequency distribution for 'intent'\n",
    "intent_counts = pd.Series([entry.get('intent', 'N/A') for entry in data]).value_counts()\n",
    "print(\"\\nIntent Frequency Distribution:\")\n",
    "print(intent_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "intent_counts.plot(kind='bar')\n",
    "plt.title('Frequency Distribution of Intent')\n",
    "plt.xlabel('Intent')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424891e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_counts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7455b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze text lengths in conversation turns to find buggy data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_text_lengths = []\n",
    "transcript_text_lengths = {} # transcript_id -> list of lengths\n",
    "\n",
    "for entry in data:\n",
    "    t_id = entry.get('transcript_id', 'unknown')\n",
    "    if 'conversation' in entry:\n",
    "        lengths = []\n",
    "        for turn in entry['conversation']:\n",
    "            if 'text' in turn:\n",
    "                l = len(turn['text'])\n",
    "                all_text_lengths.append(l)\n",
    "                lengths.append(l)\n",
    "        transcript_text_lengths[t_id] = lengths\n",
    "\n",
    "# Convert to series for stats\n",
    "text_len_series = pd.Series(all_text_lengths)\n",
    "print(\"Text Length Statistics:\")\n",
    "print(text_len_series.describe())\n",
    "\n",
    "# Define threshold for \"abnormally long\"\n",
    "# Using 99.9th percentile to catch extreme outliers which might be buggy\n",
    "threshold = text_len_series.quantile(0.999)\n",
    "print(f\"\\nThreshold for abnormal length (99.9th percentile): {threshold:.2f}\")\n",
    "\n",
    "# Find transcripts with abnormal text lengths\n",
    "flagged_transcripts = []\n",
    "for t_id, lengths in transcript_text_lengths.items():\n",
    "    max_len = max(lengths) if lengths else 0\n",
    "    if max_len > threshold:\n",
    "        flagged_transcripts.append({\n",
    "            'transcript_id': t_id,\n",
    "            'max_text_length': max_len\n",
    "        })\n",
    "\n",
    "print(f\"\\nFound {len(flagged_transcripts)} transcripts with abnormally long text fields (> {threshold:.2f} chars).\")\n",
    "\n",
    "# Sort by max length to see the worst offenders\n",
    "flagged_transcripts.sort(key=lambda x: x['max_text_length'], reverse=True)\n",
    "\n",
    "print(\"\\nTop 10 Flagged Transcripts:\")\n",
    "for item in flagged_transcripts[:10]:\n",
    "    print(f\"ID: {item['transcript_id']}, Max Length: {item['max_text_length']}\")\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_text_lengths, bins=50, log=True, edgecolor='black')\n",
    "plt.title('Distribution of Text Lengths in Conversation Turns (Log Scale)')\n",
    "plt.xlabel('Length of Text')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(threshold, color='r', linestyle='dashed', linewidth=1, label=f'Threshold ({threshold:.0f})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter transcripts with text length > 300\n",
    "filtered_data = []\n",
    "removed_ids = []\n",
    "threshold = 300\n",
    "\n",
    "for entry in data:\n",
    "    t_id = entry.get('transcript_id', 'unknown')\n",
    "    should_remove = False\n",
    "    if 'conversation' in entry:\n",
    "        for turn in entry['conversation']:\n",
    "            if 'text' in turn and len(turn['text']) > threshold:\n",
    "                should_remove = True\n",
    "                break\n",
    "    \n",
    "    if should_remove:\n",
    "        removed_ids.append(t_id)\n",
    "    else:\n",
    "        filtered_data.append(entry)\n",
    "\n",
    "# Save to a new file\n",
    "output_filename = \"transcripts_filtered.json\"\n",
    "with open(output_filename, \"w\") as f:\n",
    "    json.dump(filtered_data, f, indent=2)\n",
    "\n",
    "print(f\"Original count: {len(data)}\")\n",
    "print(f\"Filtered count: {len(filtered_data)}\")\n",
    "print(f\"Removed {len(removed_ids)} transcripts.\")\n",
    "print(\"Removed IDs:\")\n",
    "print(removed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze text length on filtered version\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"transcripts_filtered.json\", \"r\") as file:\n",
    "\tdata_filtered = json.load(file)\n",
    "    \n",
    "all_text_lengths = []\n",
    "transcript_text_lengths = {} # transcript_id -> list of lengths\n",
    "\n",
    "for entry in data_filtered:\n",
    "    t_id = entry.get('transcript_id', 'unknown')\n",
    "    if 'conversation' in entry:\n",
    "        lengths = []\n",
    "        for turn in entry['conversation']:\n",
    "            if 'text' in turn:\n",
    "                l = len(turn['text'])\n",
    "                all_text_lengths.append(l)\n",
    "                lengths.append(l)\n",
    "        transcript_text_lengths[t_id] = lengths\n",
    "\n",
    "# Convert to series for stats\n",
    "text_len_series = pd.Series(all_text_lengths)\n",
    "print(\"Text Length Statistics:\")\n",
    "print(text_len_series.describe())\n",
    "\n",
    "# Define threshold for \"abnormally long\"\n",
    "# Using 99.9th percentile to catch extreme outliers which might be buggy\n",
    "threshold = text_len_series.quantile(0.999)\n",
    "print(f\"\\nThreshold for abnormal length (99.9th percentile): {threshold:.2f}\")\n",
    "\n",
    "# Find transcripts with abnormal text lengths\n",
    "flagged_transcripts = []\n",
    "for t_id, lengths in transcript_text_lengths.items():\n",
    "    max_len = max(lengths) if lengths else 0\n",
    "    if max_len > threshold:\n",
    "        flagged_transcripts.append({\n",
    "            'transcript_id': t_id,\n",
    "            'max_text_length': max_len\n",
    "        })\n",
    "\n",
    "print(f\"\\nFound {len(flagged_transcripts)} transcripts with abnormally long text fields (> {threshold:.2f} chars).\")\n",
    "\n",
    "# Sort by max length to see the worst offenders\n",
    "flagged_transcripts.sort(key=lambda x: x['max_text_length'], reverse=True)\n",
    "\n",
    "print(\"\\nTop 10 Flagged Transcripts:\")\n",
    "for item in flagged_transcripts[:10]:\n",
    "    print(f\"ID: {item['transcript_id']}, Max Length: {item['max_text_length']}\")\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_text_lengths, bins=50, log=True, edgecolor='black')\n",
    "plt.title('Distribution of Text Lengths in Conversation Turns (Log Scale)')\n",
    "plt.xlabel('Length of Text')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(threshold, color='r', linestyle='dashed', linewidth=1, label=f'Threshold ({threshold:.0f})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e299f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"clean_transcripts.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ed64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_text_lengths = []\n",
    "transcript_text_lengths = {} # transcript_id -> list of lengths\n",
    "\n",
    "for entry in data:\n",
    "    t_id = entry.get('transcript_id', 'unknown')\n",
    "    if 'conversation' in entry:\n",
    "        lengths = []\n",
    "        for turn in entry['conversation']:\n",
    "            if 'text' in turn:\n",
    "                l = len(turn['text'])\n",
    "                all_text_lengths.append(l)\n",
    "                lengths.append(l)\n",
    "        transcript_text_lengths[t_id] = lengths\n",
    "\n",
    "# Convert to series for stats\n",
    "text_len_series = pd.Series(all_text_lengths)\n",
    "print(\"Text Length Statistics:\")\n",
    "print(text_len_series.describe())\n",
    "\n",
    "# Define threshold for \"abnormally long\"\n",
    "# Using 99.9th percentile to catch extreme outliers which might be buggy\n",
    "threshold = text_len_series.quantile(0.999)\n",
    "print(f\"\\nThreshold for abnormal length (99.9th percentile): {threshold:.2f}\")\n",
    "\n",
    "# Find transcripts with abnormal text lengths\n",
    "flagged_transcripts = []\n",
    "for t_id, lengths in transcript_text_lengths.items():\n",
    "    max_len = max(lengths) if lengths else 0\n",
    "    if max_len > threshold:\n",
    "        flagged_transcripts.append({\n",
    "            'transcript_id': t_id,\n",
    "            'max_text_length': max_len\n",
    "        })\n",
    "\n",
    "print(f\"\\nFound {len(flagged_transcripts)} transcripts with abnormally long text fields (> {threshold:.2f} chars).\")\n",
    "\n",
    "# Sort by max length to see the worst offenders\n",
    "flagged_transcripts.sort(key=lambda x: x['max_text_length'], reverse=True)\n",
    "\n",
    "print(\"\\nTop 10 Flagged Transcripts:\")\n",
    "for item in flagged_transcripts[:10]:\n",
    "    print(f\"ID: {item['transcript_id']}, Max Length: {item['max_text_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_count = 0\n",
    "for transcript in data:\n",
    "    if 'conversation' not in transcript or not transcript['conversation']:\n",
    "        continue\n",
    "\n",
    "    # Create a new list to hold the merged turns\n",
    "    new_conversation = []\n",
    "    \n",
    "    # Add the first turn to the new list\n",
    "    # We use .copy() to ensure we are creating a new dictionary object for the merged list\n",
    "    if len(transcript['conversation']) > 0:\n",
    "        new_conversation.append(transcript['conversation'][0].copy())\n",
    "\n",
    "    # Iterate through the rest of the turns\n",
    "    for turn in transcript['conversation'][1:]:\n",
    "        # Get the last turn added to the new list\n",
    "        last_turn = new_conversation[-1]\n",
    "        \n",
    "        # Check if the current turn's speaker is the same as the last turn's speaker\n",
    "        if turn['speaker'] == last_turn['speaker']:\n",
    "            # If same speaker, merge the text into the last turn\n",
    "            last_turn['text'] += \". \" + turn['text']\n",
    "            merged_count += 1\n",
    "            # We do NOT append 'turn' to new_conversation, effectively deleting it\n",
    "        else:\n",
    "            # If different speaker, add the turn to the new list\n",
    "            new_conversation.append(turn.copy())\n",
    "    \n",
    "    # Update the transcript with the merged conversation\n",
    "    transcript['conversation'] = new_conversation\n",
    "\n",
    "print(f\"Merged {merged_count} turns where consecutive speakers were the same.\")\n",
    "\n",
    "# Save the modified data to a new JSON file\n",
    "output_file = \"clean_transcripts_merged.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"Modified data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"final_clean_transcripts.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952456f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript in data:\n",
    "    prev_speaker = None\n",
    "    for i,turn in enumerate(transcript['conversation']):\n",
    "        if prev_speaker == None:\n",
    "            prev_speaker = turn['speaker']\n",
    "            continue\n",
    "        if turn[\"speaker\"] == prev_speaker:\n",
    "            print(f\"Transcript ID: {transcript['transcript_id']} | Turn Index: {i} | Speaker: {turn['speaker']}\")\n",
    "        prev_speaker = turn['speaker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e161c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6143945",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_clean_transcripts.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
