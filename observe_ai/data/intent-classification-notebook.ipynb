{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13930710,"sourceType":"datasetVersion","datasetId":8877477}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:25:52.166994Z","iopub.execute_input":"2025-11-30T14:25:52.167300Z","iopub.status.idle":"2025-11-30T14:29:55.687255Z","shell.execute_reply.started":"2025-11-30T14:25:52.167278Z","shell.execute_reply":"2025-11-30T14:29:55.686128Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.11.4-py3-none-any.whl.metadata (64 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.11.4 (from unsloth)\n  Downloading unsloth_zoo-2025.11.5-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.1.3)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (6.33.0)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\nCollecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nCollecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.9.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.16.0)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.53.3)\nCollecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\nCollecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\nCollecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (0.21.2)\nCollecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 (from unsloth)\n  Downloading transformers-4.57.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.4->unsloth)\n  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.11.4->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.11.4->unsloth) (11.3.0)\nCollecting msgspec (from unsloth_zoo>=2025.11.4->unsloth)\n  Downloading msgspec-0.20.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n  Downloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.17.0)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.2.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.8.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\nDownloading unsloth-2025.11.4-py3-none-any.whl (358 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m358.7/358.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.57.2-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.11.5-py3-none-any.whl (284 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.4/284.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.8.0-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.20.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (219 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.9/219.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchao, nvidia-cusparselt-cu12, triton, sympy, shtab, pyarrow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, tokenizers, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, datasets, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: torchao\n    Found existing installation: torchao 0.10.0\n    Uninstalling torchao-0.10.0:\n      Successfully uninstalled torchao-0.10.0\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.18\n    Uninstalling multiprocess-0.70.18:\n      Successfully uninstalled multiprocess-0.70.18\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.10.0\n    Uninstalling fsspec-2025.10.0:\n      Successfully uninstalled fsspec-2025.10.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.9.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 fsspec-2025.9.0 msgspec-0.20.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pyarrow-22.0.0 shtab-1.8.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 torchao-0.14.1 torchvision-0.24.0 transformers-4.57.2 triton-3.5.0 trl-0.24.0 tyro-0.9.35 unsloth-2025.11.4 unsloth_zoo-2025.11.5 xformers-0.0.33.post1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from unsloth import FastLanguageModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:30:33.339714Z","iopub.execute_input":"2025-11-30T14:30:33.339964Z","iopub.status.idle":"2025-11-30T14:30:37.108672Z","shell.execute_reply.started":"2025-11-30T14:30:33.339948Z","shell.execute_reply":"2025-11-30T14:30:37.107969Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/2814113929.py:1: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n\nPlease restructure your imports with 'import unsloth' at the top of your file.\n  from unsloth import FastLanguageModel\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import json\nimport torch\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import pairwise_distances_argmin_min\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom sentence_transformers import SentenceTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:30:41.053925Z","iopub.execute_input":"2025-11-30T14:30:41.054722Z","iopub.status.idle":"2025-11-30T14:30:41.058747Z","shell.execute_reply.started":"2025-11-30T14:30:41.054695Z","shell.execute_reply":"2025-11-30T14:30:41.057894Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# --- Configuration ---\nDATA_PATH = \"/kaggle/input/interiit-25-observe-ai-transcripts/transcripts.json\"      # Path to your JSON file\nNUM_SAMPLES = 35                    # Number of diverse transcripts to send to LLM\n# MODEL_ID = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\" # Local 4-bit quantized model\nMODEL_ID = \"unsloth/Qwen3-14B-unsloth-bnb-4bit\"\n# MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct-AWQ\"       # Alternative\nEMBEDDING_BATCH_SIZE = 512          # Batch size for generating embeddings (adjust based on VRAM)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:30:49.828223Z","iopub.execute_input":"2025-11-30T14:30:49.828520Z","iopub.status.idle":"2025-11-30T14:30:49.832589Z","shell.execute_reply.started":"2025-11-30T14:30:49.828477Z","shell.execute_reply":"2025-11-30T14:30:49.831923Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"LLM_MODEL, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=MODEL_ID,\n    max_seq_length=4096*4,\n    dtype=None,\n    load_in_4bit=True,\n    device_map = \"balanced\"\n)\nFastLanguageModel.for_inference(LLM_MODEL)  # âœ… Enable faster inference","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:31:13.963716Z","iopub.execute_input":"2025-11-30T14:31:13.964292Z","iopub.status.idle":"2025-11-30T14:32:15.187859Z","shell.execute_reply.started":"2025-11-30T14:31:13.964269Z","shell.execute_reply":"2025-11-30T14:32:15.187065Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.11.4: Fast Qwen3 patching. Transformers: 4.57.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aabecef2dee4b13be6d0fc323976d53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65a75876dfa4f05b652d5f8e8b131df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.59G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58539fd5ee4c4827b8283e51fd090682"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"105e0b02ebae4798ad8a1d03c031b52d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3349fdaebd3845d0a2f7c19f0cdab171"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fde6cb5a94c408098059532b7fa4585"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Qwen3ForCausalLM(\n  (model): Qwen3Model(\n    (embed_tokens): Embedding(151936, 5120, padding_idx=151654)\n    (layers): ModuleList(\n      (0-5): 6 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n      )\n      (6): Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n          (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n          (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n      )\n      (7-18): 12 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n      )\n      (19): Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n          (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n          (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n      )\n      (20-37): 18 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n      )\n      (38): Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n          (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n          (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n      )\n      (39): Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# --- Helper: Convert JSON Transcript to String ---\ndef transcript_to_string(record):\n    \"\"\"\n    Converts the structured conversation list into a readable string.\n    Includes metadata like 'reason_for_call' to help the embedding model.\n    \"\"\"\n    # 1. Start with metadata context (Very helpful for clustering)\n    text_representation = f\"Reason for call: {record.get('reason_for_call', 'N/A')}\\n\"\n    \n    # 2. Append the dialogue\n    for turn in record['conversation']:\n        text_representation += f\"{turn['speaker']}: {turn['text']}\\n\"\n        \n    return text_representation\n\n# --- Step 1: Smart Diversity Sampling ---\ndef get_diverse_samples(json_data, n_samples=50):\n    print(f\"--- 1. Embeddings & Clustering (Total Records: {len(json_data)}) ---\")\n    \n    # 1. Prepare texts\n    print(\"Preparing text representations...\")\n    all_texts = [transcript_to_string(record) for record in json_data]\n    \n    # 2. Embed using a lightweight local model with GPU acceleration\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Embedding transcripts using all-MiniLM-L6-v2 on {device} with batch size {EMBEDDING_BATCH_SIZE}...\")\n    \n    embedder = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n    embeddings = embedder.encode(\n        all_texts, \n        batch_size=EMBEDDING_BATCH_SIZE, \n        show_progress_bar=True,\n        convert_to_numpy=True\n    )\n    \n    # 3. Cluster to find diversity\n    print(f\"Clustering into {n_samples} clusters...\")\n    kmeans = KMeans(n_clusters=n_samples, random_state=42, n_init=10)\n    kmeans.fit(embeddings)\n    \n    # 4. Find the transcript closest to the center of each cluster\n    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, embeddings)\n    \n    # selected_records = [json_data[i] for i in closest]\n    selected_texts = [all_texts[i] for i in closest]\n    \n    print(f\"Selected {len(selected_texts)} diverse transcripts.\")\n    return selected_texts\n\n# --- Step 2: LLM Taxonomy Generation ---\ndef generate_taxonomy_with_llm(sample_texts):\n    print(\"\\n--- 2. Loading Quantized LLM ---\")\n    \n    # 1. Load 4-bit Quantized Model\n    # device_map=\"auto\" automatically uses GPU if available\n    # model, tokenizer = FastLanguageModel.from_pretrained(\n    #     model_name=MODEL_ID,\n    #     # max_seq_length=4096*2,\n    #     dtype=None,\n    #     load_in_4bit=True,\n    # )\n    # FastLanguageModel.for_inference(LLM_MODEL)  # âœ… Enable faster inference\n    \n    print(\"LLM Loaded. Generating Taxonomy...\")\n\n    # 2. Prepare the prompt (Chunking if necessary, but 50 short transcripts usually fit 8k context)\n    # If 50 is too large for context, we take the first 15-20 most distinct ones.\n    # Let's use the first 15 for the prompt to be safe on context limits.\n    prompt_samples = sample_texts[:25]\n    \n    formatted_samples = \"\"\n    for i, text in enumerate(prompt_samples):\n        formatted_samples += f\"\\n--- TRANSCRIPT {i+1} ---\\n{text[:1500]}...\" # Truncate slightly if super long\n\n    system_prompt = \"\"\"You are an expert Data Taxonomist building an 'Intent Graph' for a retrieval system.\n    \n    Your task is to analyze customer service transcripts and generate a **Hierarchical Intent Taxonomy**.\n    \n    ### DEFINITIONS:\n    1. **Primary Intent**: The broad category of the conversation (e.g., Billing, Scheduling).\n    2. **Secondary Intent**: The specific granular action taken in a single turn.\n       - **User Intents**: What the customer is trying to do (e.g., \"Reject Offer\", \"Complain about Delay\").\n       - **Agent Intents**: What the agent is trying to do (e.g., \"Propose Alternative\", \"Verify Identity\").\n    \n    ### FEW-SHOT EXAMPLES (Follow this granularity):\n    \n    **Example 1: Scheduling Domain**\n    Output JSON:\n    {\n      \"Service Scheduling\": {\n         \"user\": [\"Request Appointment\", \"Reject Proposed Time\", \"Confirm Time\"],\n         \"agent\": [\"Propose Time Slot\", \"Offer Alternative Location\", \"Confirm Booking\"]\n      }\n    }\n    \n    **Example 2: Billing Domain**\n    Output JSON:\n    {\n      \"Billing & Refunds\": {\n         \"user\": [\"Dispute Charge\", \"Request Refund Status\", \"Threaten Churn\"],\n         \"agent\": [\"Explain Charge\", \"Process Refund\", \"Deny Request Policy\"]\n      }\n    }\n\n    ### INSTRUCTIONS:\n    - Analyze the provided transcripts to discover the Domain-Specific intents.\n    - **CRITICAL:** You MUST generate both 'user' and 'agent' lists for every Primary Intent.\n    - Output ONLY valid JSON.\n    \"\"\"\n    \n    user_msg = f\"\"\"Here are diverse transcripts from the dataset. Analyze them and produce the JSON taxonomy.\n    \n    {formatted_samples}\n    \"\"\"\n\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_msg},\n    ]\n\n    # 3. Generate\n    # Explicitly move inputs to CUDA to ensure they match the model device\n    prompt = tokenizer.apply_chat_template(\n        messages, tokenize=False, add_generation_prompt=True, enable_thinking=True\n    )\n    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(LLM_MODEL.device)\n \n    generated_ids = LLM_MODEL.generate(\n        **inputs,  # âœ… Unpack inputs dict\n        max_new_tokens=2048,\n        temperature=0.1,\n        do_sample=True\n    )\n    output_ids = generated_ids[0][len(inputs.input_ids[0]):].tolist() \n    # return \"response\" to directly get model outputs string\n    # response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n    return output_ids","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:29:03.181872Z","iopub.execute_input":"2025-11-30T15:29:03.182171Z","iopub.status.idle":"2025-11-30T15:29:03.193093Z","shell.execute_reply.started":"2025-11-30T15:29:03.182150Z","shell.execute_reply":"2025-11-30T15:29:03.192414Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# --- Main Execution Flow ---\n# 1. Load Data\ntry:\n    with open(DATA_PATH, 'r') as f:\n        full_data = json.load(f)\n        # Handle case where json is a list of records directly\n        # or if it's wrapped in a key like {\"transcripts\": [...]}\n        if isinstance(full_data, dict) and \"transcripts\" in full_data:\n            full_data = full_data[\"transcripts\"]\nexcept FileNotFoundError:\n    print(f\"Error: {DATA_PATH} not found. Please ensure the file exists.\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:32:15.200325Z","iopub.execute_input":"2025-11-30T14:32:15.200658Z","iopub.status.idle":"2025-11-30T14:32:21.491249Z","shell.execute_reply.started":"2025-11-30T14:32:15.200637Z","shell.execute_reply":"2025-11-30T14:32:21.490522Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 2. Get Diverse Samples (The \"Smart 100\")\ndiverse_transcript_texts = get_diverse_samples(full_data, n_samples=NUM_SAMPLES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:32:21.492766Z","iopub.execute_input":"2025-11-30T14:32:21.493043Z","iopub.status.idle":"2025-11-30T14:34:00.835781Z","shell.execute_reply.started":"2025-11-30T14:32:21.493020Z","shell.execute_reply":"2025-11-30T14:34:00.834941Z"}},"outputs":[{"name":"stdout","text":"--- 1. Embeddings & Clustering (Total Records: 19621) ---\nPreparing text representations...\nEmbedding transcripts using all-MiniLM-L6-v2 on cuda with batch size 512...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d4b4ea9e499420193b13fa16919f15b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad69c85b43cd46f1b983016d2855fc8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f35b0888b154657926fc72745e1009a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7aec792afce406e9090d56820af93a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4457c7e0f1b49228abeba1a137b9ca4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e76a208565446ee88ef917f2c78b4d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"431425ac46444a1585a6a2fb532975f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d114009e4de146669384821078e60445"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5ce80eb6ab4e99aea1b3aef04d5714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9490d4f284f5406692a85e626bd1c2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"becc52211b404d8d84fb0efed95c70f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/39 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0fbac865947468994bfed07055747a3"}},"metadata":{}},{"name":"stdout","text":"Clustering into 35 clusters...\nSelected 35 diverse transcripts.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# prompt_samples = diverse_transcript_texts[:50] \n\n# formatted_samples = \"\"\n# for i, text in enumerate(prompt_samples):\n#     formatted_samples += f\"\\n--- TRANSCRIPT {i+1} ---\\n{text[:1500]}...\" # Truncate slightly if super long\n\n# system_prompt = \"\"\"You are an expert Data Taxonomist.\n# Your task is to analyze these customer service transcripts and generate a **Domain-Agnostic Intent Taxonomy**.\n\n# Identify:\n# 1. **Primary Intents**: The high-level category of the conversation (e.g., Billing, Technical Support, Sales).\n# 2. **Secondary Intents**: Specific actions taken by the User or Agent (e.g., \"Ask for Discount\", \"Reject Offer\", \"Clarify Policy\").\n\n# **CRITICAL OUTPUT RULES:**\n# - Output ONLY valid JSON.\n# - Do not write intro/outro text.\n# - Ensure 'Secondary Intents' cover both Customer and Agent actions found in the transcripts.\n\n# **JSON Structure:**\n# {\n#   \"primary_intents\": [\n#     \"Category A\",\n#     \"Category B\"\n#   ],\n#   \"secondary_intents\": {\n#     \"Category A\": [\"Action 1\", \"Action 2\"],\n#     \"Category B\": [\"Action 3\", \"Action 4\"]\n#   }\n# }\n# \"\"\"\n\n# user_msg = f\"\"\"Here are diverse transcripts from the dataset. Analyze them and produce the JSON taxonomy.\n\n# {formatted_samples}\n# \"\"\"\n\n# messages = [\n#     {\"role\": \"system\", \"content\": system_prompt},\n#     {\"role\": \"user\", \"content\": user_msg},\n# ]\n\n# # 3. Generate\n# # Explicitly move inputs to CUDA to ensure they match the model device\n# prompt = tokenizer.apply_chat_template(\n#     messages, tokenize=True, add_generation_prompt=True\n# )\n\n# print(f'total tokens: {len(prompt)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:22:27.000095Z","iopub.status.idle":"2025-11-30T14:22:27.000307Z","shell.execute_reply.started":"2025-11-30T14:22:27.000201Z","shell.execute_reply":"2025-11-30T14:22:27.000211Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Generate Taxonomy\noutput_ids = generate_taxonomy_with_llm(diverse_transcript_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:29:09.816100Z","iopub.execute_input":"2025-11-30T15:29:09.816776Z","iopub.status.idle":"2025-11-30T15:38:09.696634Z","shell.execute_reply.started":"2025-11-30T15:29:09.816752Z","shell.execute_reply":"2025-11-30T15:38:09.695991Z"}},"outputs":[{"name":"stdout","text":"\n--- 2. Loading Quantized LLM ---\nLLM Loaded. Generating Taxonomy...\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ntaxonomy_json_str = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:38:09.697978Z","iopub.execute_input":"2025-11-30T15:38:09.698248Z","iopub.status.idle":"2025-11-30T15:38:09.704097Z","shell.execute_reply.started":"2025-11-30T15:38:09.698225Z","shell.execute_reply":"2025-11-30T15:38:09.703589Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# 4. Save Output\nprint(\"\\n--- Generated Taxonomy ---\")\nprint(taxonomy_json_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:38:09.704725Z","iopub.execute_input":"2025-11-30T15:38:09.704997Z","iopub.status.idle":"2025-11-30T15:38:09.723352Z","shell.execute_reply.started":"2025-11-30T15:38:09.704972Z","shell.execute_reply":"2025-11-30T15:38:09.722712Z"}},"outputs":[{"name":"stdout","text":"\n--- Generated Taxonomy ---\n{\n  \"Billing & Refunds\": {\n    \"user\": [\"Dispute Charge\", \"Request Refund Status\", \"Threaten Churn\", \"Inquire About Billing Discrepancies\"],\n    \"agent\": [\"Explain Charge\", \"Process Refund\", \"Deny Request Policy\", \"Investigate Billing Issue\"]\n  },\n  \"Insurance Renewal\": {\n    \"user\": [\"Inquire About Renewal Options\", \"Express Concern About Costs\", \"Request Policy Clarification\"],\n    \"agent\": [\"Explain Policy Options\", \"Discuss Incentives\", \"Clarify Coverage Limits\"]\n  },\n  \"Order Delivery\": {\n    \"user\": [\"Check Delivery Status\", \"Complain About Delay\", \"Request Carrier Info\"],\n    \"agent\": [\"Provide Delivery Update\", \"Offer Carrier Info\", \"Apologize for Delays\"]\n  },\n  \"Flight Rebooking\": {\n    \"user\": [\"Request Rebooking Options\", \"Inquire About Compensation\", \"Express Urgency\"],\n    \"agent\": [\"Provide Rebooking Options\", \"Offer Compensation\", \"Explain Delay Policies\"]\n  },\n  \"Service Outage\": {\n    \"user\": [\"Report Outage\", \"Ask About Resolution Time\", \"Compare With Competitors\"],\n    \"agent\": [\"Provide Outage Info\", \"Offer Updates\", \"Diagnose Technical Issues\"]\n  },\n  \"Cancellation Policy\": {\n    \"user\": [\"Inquire About Cancellation Options\", \"Ask About Reinstatement\", \"Request Policy Clarification\"],\n    \"agent\": [\"Explain Cancellation Policy\", \"Discuss Reinstatement\", \"Clarify Terms\"]\n  },\n  \"Loyalty Program Benefits\": {\n    \"user\": [\"Inquire About Benefits\", \"Ask About Tier Perks\", \"Compare With Competitors\"],\n    \"agent\": [\"Explain Loyalty Tiers\", \"Clarify Benefits\", \"Provide Promo Codes\"]\n  },\n  \"Hotel Complaint\": {\n    \"user\": [\"Report Cleanliness Issues\", \"Compare With Competitors\", \"Request Resolution\"],\n    \"agent\": [\"Apologize for Issues\", \"Offer Resolution\", \"Investigate Complaint\"]\n  },\n  \"Product Defect Resolution\": {\n    \"user\": [\"Report Defective Item\", \"Request Replacement\", \"Inquire About Return Process\"],\n    \"agent\": [\"Offer Replacement/Refund\", \"Provide Return Label\", \"Expedite Resolution\"]\n  },\n  \"Room Upgrade\": {\n    \"user\": [\"Request Upgrade\", \"Inquire About Pricing\", \"Compare With Competitors\"],\n    \"agent\": [\"Offer Upgrade Options\", \"Explain Loyalty Benefits\", \"Clarify Eligibility\"]\n  },\n  \"Fraud Reporting\": {\n    \"user\": [\"Report Suspected Fraud\", \"Request Verification\", \"Inquire About Investigation\"],\n    \"agent\": [\"Verify Identity\", \"Initiate Investigation\", \"Provide Security Measures\"]\n  },\n  \"Insurance Plan Upgrade\": {\n    \"user\": [\"Inquire About Upgrade Options\", \"Ask About Cost\", \"Compare With Competitors\"],\n    \"agent\": [\"Explain Plan Differences\", \"Discuss Premiums\", \"Offer Discounts\"]\n  },\n  \"Credit Limit Adjustment\": {\n    \"user\": [\"Request Credit Limit Increase\", \"Question Approval\", \"Inquire About Policies\"],\n    \"agent\": [\"Offer Partial Increase\", \"Explain Policies\", \"Clarify Eligibility\"]\n  },\n  \"Service Switching\": {\n    \"user\": [\"Express Dissatisfaction\", \"Inquire About Retention Offers\", \"Compare With Competitors\"],\n    \"agent\": [\"Offer Retention Options\", \"Discuss Plan Upgrades\", \"Provide Discounts\"]\n  },\n  \"Technical Support\": {\n    \"user\": [\"Report Connectivity Issues\", \"Request Troubleshooting\", \"Inquire About Speeds\"],\n    \"agent\": [\"Diagnose Issue\", \"Provide Troubleshooting Steps\", \"Explain Plan Limits\"]\n  },\n  \"Booking Error Resolution\": {\n    \"user\": [\"Report Double Booking\", \"Request Resolution\", \"Inquire About Delays\"],\n    \"agent\": [\"Investigate Booking Error\", \"Offer Resolution\", \"Expedite Fix\"]\n  },\n  \"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Clean code block markers if LLM adds them\nclean_json = taxonomy_json_str.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n\nwith open(\"taxonomy.json\", \"w\") as f:\n    f.write(clean_json)\nprint(\"\\n[Saved] Taxonomy saved to taxonomy.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:38:09.724572Z","iopub.execute_input":"2025-11-30T15:38:09.724788Z","iopub.status.idle":"2025-11-30T15:38:09.734624Z","shell.execute_reply.started":"2025-11-30T15:38:09.724773Z","shell.execute_reply":"2025-11-30T15:38:09.734104Z"}},"outputs":[{"name":"stdout","text":"\n[Saved] Taxonomy saved to taxonomy.json\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}