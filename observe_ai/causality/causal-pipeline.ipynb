{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13976980,"sourceType":"datasetVersion","datasetId":8910529},{"sourceId":13977202,"sourceType":"datasetVersion","datasetId":8910630},{"sourceId":13977315,"sourceType":"datasetVersion","datasetId":8910678},{"sourceId":13977920,"sourceType":"datasetVersion","datasetId":8910962}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:04:24.420686Z","iopub.execute_input":"2025-12-04T05:04:24.421008Z","iopub.status.idle":"2025-12-04T05:08:29.038168Z","shell.execute_reply.started":"2025-12-04T05:04:24.420986Z","shell.execute_reply":"2025-12-04T05:08:29.037259Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.11.6-py3-none-any.whl.metadata (64 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.11.6 (from unsloth)\n  Downloading unsloth_zoo-2025.11.6-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.1.3)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (6.33.0)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\nCollecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nCollecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.9.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.16.0)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.53.3)\nCollecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\nCollecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\nCollecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (0.21.2)\nCollecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 (from unsloth)\n  Downloading transformers-4.57.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.6->unsloth)\n  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.11.6->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.11.6->unsloth) (11.3.0)\nCollecting msgspec (from unsloth_zoo>=2025.11.6->unsloth)\n  Downloading msgspec-0.20.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n  Downloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.17.0)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.2.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.8.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\nDownloading unsloth-2025.11.6-py3-none-any.whl (359 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m359.3/359.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.57.2-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.11.6-py3-none-any.whl (289 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.8.0-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.20.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (219 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.9/219.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchao, nvidia-cusparselt-cu12, triton, sympy, shtab, pyarrow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, tokenizers, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, datasets, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: torchao\n    Found existing installation: torchao 0.10.0\n    Uninstalling torchao-0.10.0:\n      Successfully uninstalled torchao-0.10.0\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.18\n    Uninstalling multiprocess-0.70.18:\n      Successfully uninstalled multiprocess-0.70.18\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.10.0\n    Uninstalling fsspec-2025.10.0:\n      Successfully uninstalled fsspec-2025.10.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.9.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 fsspec-2025.9.0 msgspec-0.20.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pyarrow-22.0.0 shtab-1.8.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 torchao-0.14.1 torchvision-0.24.0 transformers-4.57.2 triton-3.5.0 trl-0.24.0 tyro-0.9.35 unsloth-2025.11.6 unsloth_zoo-2025.11.6 xformers-0.0.33.post1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install xgboost networkx scikit-learn --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:09:31.433892Z","iopub.execute_input":"2025-12-04T05:09:31.434198Z","iopub.status.idle":"2025-12-04T05:09:34.925990Z","shell.execute_reply.started":"2025-12-04T05:09:31.434168Z","shell.execute_reply":"2025-12-04T05:09:34.925209Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import json\nimport numpy as np\nimport pandas as pd\nimport joblib\n\nfrom unsloth import FastLanguageModel\nimport torch\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:09:39.381395Z","iopub.execute_input":"2025-12-04T05:09:39.381641Z","iopub.status.idle":"2025-12-04T05:10:10.900315Z","shell.execute_reply.started":"2025-12-04T05:09:39.381620Z","shell.execute_reply":"2025-12-04T05:10:10.899717Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-12-04 05:09:45.427267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764824985.622760      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764824985.674501      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ==== CONFIG ====\nDATA_PATH = \"/kaggle/input/new-observational-data/NewObservationalDataset.csv\"\nSCHEMA_PATH = \"/kaggle/input/variable-schema-fixed-clean/variable_schema_fixed_clean.json\"              # from your previous step\nSCM_BUNDLE_PATH = \"/kaggle/input/sgm-xgboost-gpu/scm_xgboost_gpu.pkl\"           # adjust if saved elsewhere\nMODEL_ID = \"unsloth/Mistral-7B-Instruct-v0.3-bnb-4bit\"      # change if you use a different Unsloth model\n\n# 4 test transcripts you chose (fill in your real IDs here)\nTEST_TRANSCRIPT_IDS = [\n    \"1c99b47c-4e80-49d5-b3c6-52b0c3230fa8\",\n]\n\n# Your test query (edit this)\nUSER_QUERY = \"How would the interaction have changed if the agent had apologized at the moment the customer first expressed frustration?\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:10:12.704249Z","iopub.execute_input":"2025-12-04T05:10:12.704538Z","iopub.status.idle":"2025-12-04T05:10:12.708847Z","shell.execute_reply.started":"2025-12-04T05:10:12.704515Z","shell.execute_reply":"2025-12-04T05:10:12.708081Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ==== LOAD UNSLOTH MISTRAL ====\nprint(\"Loading Unsloth Mistral...\")\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = MODEL_ID,\n    max_seq_length = 4096,\n    dtype = None,\n    load_in_4bit = True,\n    device_map = \"balanced\",\n)\nFastLanguageModel.for_inference(model)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:10:15.111128Z","iopub.execute_input":"2025-12-04T05:10:15.111409Z","iopub.status.idle":"2025-12-04T05:11:25.874194Z","shell.execute_reply.started":"2025-12-04T05:10:15.111389Z","shell.execute_reply":"2025-12-04T05:11:25.873306Z"}},"outputs":[{"name":"stdout","text":"Loading Unsloth Mistral...\n==((====))==  Unsloth 2025.11.6: Fast Mistral patching. Transformers: 4.57.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.14G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"796ab1f5bd8847df9c3e6ed6375b22ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/157 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f85e3ec30749f5924796c81ebfc919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"156aaed8506a4fcfa3e8741e7fd37c24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44edcab10c134f32b3cde55d6253ca1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fe832d77ee84260a803529c41ec27aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"736ff99d39014ead953e738fbe59ddbc"}},"metadata":{}},{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ==== LOAD VARIABLE SCHEMA ====\nwith open(SCHEMA_PATH, \"r\", encoding=\"utf-8\") as f:\n    schema = json.load(f)\n\n# Map var name -> schema entry for easy lookup\nschema_by_name = {v[\"name\"]: v for v in schema}\n\n# List of numeric variable names (from schema)\nNUMERIC_VARS = [v[\"name\"] for v in schema]\n\n\n# ==== LOAD DATASET ====\ndf_full = pd.read_csv(DATA_PATH)\nprint(\"Full dataset shape:\", df_full.shape)\n\n# Ensure all numeric vars exist\nmissing = [c for c in NUMERIC_VARS if c not in df_full.columns]\nif missing:\n    print(\"WARNING: These schema vars not in dataset:\", missing)\n\n# Numeric-only view used for SCM (same columns as used in training)\ndf_numeric = df_full[NUMERIC_VARS].copy()\nprint(\"Numeric df shape:\", df_numeric.shape)\n\n\n# ==== LOAD SCM BUNDLE (XGBoost SCM) ====\nbundle = joblib.load(SCM_BUNDLE_PATH)\nscm_models = bundle[\"scm_models\"]\ntopo_order = bundle[\"topo_order\"]\n\n# Simulation function (if you don't already have it in your notebook)\ndef simulate_scm(base_row, interventions, scm_bundle):\n    \"\"\"\n    base_row: pd.Series with numeric vars only.\n    interventions: dict { var_name: new_value }\n    scm_bundle: dict with \"scm_models\", \"topo_order\"\n    \"\"\"\n    scm_models = scm_bundle[\"scm_models\"]\n    topo_order = scm_bundle[\"topo_order\"]\n\n    x = base_row.copy()\n\n    # apply interventions\n    for var, val in interventions.items():\n        if var not in x.index:\n            raise ValueError(f\"Intervened variable '{var}' not found in base_row.\")\n        x[var] = val\n\n    # propagate\n    for node in topo_order:\n        if node in interventions:\n            continue  # intervened variables stay fixed\n\n        model_info = scm_models.get(node, None)\n        if model_info is None:\n            continue  # root or missing model\n\n        parents = model_info[\"parents\"]\n        model = model_info[\"model\"]\n        parent_vals = np.array([x[p] for p in parents], dtype=float).reshape(1, -1)\n        x[node] = float(model.predict(parent_vals)[0])\n\n    return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:11:31.259323Z","iopub.execute_input":"2025-12-04T05:11:31.259610Z","iopub.status.idle":"2025-12-04T05:11:32.252764Z","shell.execute_reply.started":"2025-12-04T05:11:31.259589Z","shell.execute_reply":"2025-12-04T05:11:32.251927Z"}},"outputs":[{"name":"stdout","text":"Full dataset shape: (19615, 41)\nNumeric df shape: (19615, 35)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ==== BUILD PROMPT FOR QUERY INTERPRETATION ====\ndef build_schema_text(schema):\n    lines = []\n    for v in schema:\n        lines.append(\n            f\"- name: {v['name']}\\n\"\n            f\"  display_name: {v['display_name']}\\n\"\n            f\"  role: {v['role']}\\n\"\n            f\"  description: {v['description']}\\n\"\n        )\n    return \"\\n\".join(lines)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:11:38.035279Z","iopub.execute_input":"2025-12-04T05:11:38.036104Z","iopub.status.idle":"2025-12-04T05:11:38.041007Z","shell.execute_reply.started":"2025-12-04T05:11:38.036067Z","shell.execute_reply":"2025-12-04T05:11:38.040153Z"},"scrolled":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def make_query_interpret_prompt(user_query, schema):\n    def build_schema_text(schema):\n        lines = []\n        for v in schema:\n            lines.append(\n                f\"- name: {v['name']}\\n\"\n                f\"  display_name: {v['display_name']}\\n\"\n                f\"  role: {v['role']}\\n\"\n                f\"  description: {v['description']}\\n\"\n            )\n        return \"\\n\".join(lines)\n\n    schema_text = build_schema_text(schema)\n\n    prompt = f\"\"\"You are a causal query interpreter.\n\nUser's question:\n\\\"\\\"\\\"{user_query}\\\"\\\"\\\"\n\nYou are given a list of numeric variables you can intervene on or measure:\n\n{schema_text}\n\nYour job:\n1. Decide which variables the user implicitly wants to INTERVENE on (change), if any.\n2. Decide which variables should be the TARGET outcomes of interest.\n3. For each intervention, specify:\n   - \"variable\": one of the 'name' fields from the list above (use exact name)\n   - \"direction\": \"increase\", \"decrease\", or \"set\"\n   - \"magnitude\": \"small\", \"medium\", \"large\", or \"exact\"\n\n4. Classify the query_type as one of:\n   - \"descriptive\"      â†’ asking to describe or explain what is happening\n   - \"predictive\"       â†’ asking what will happen without changing anything\n   - \"interventional\"   â†’ asking about the effect of changing a variable in general\n   - \"counterfactual\"   â†’ asking what would have happened in this specific call if something had been different\n\nIf the user is only asking for an explanation of what is happening (no change), then:\n- query_type should be \"descriptive\"\n- \"interventions\" should be an empty list []\n- \"targets\" should list the most relevant variables to describe.\n\nImportant rules:\n- Use ONLY variable names from the provided list for \"variable\" and in \"targets\".\n- Do NOT invent new variable names.\n- If no clear intervention is implied, leave \"interventions\": [].\n- Always output valid JSON.\n\nOutput STRICTLY in this JSON format and nothing else:\n\n{{\n  \"query_type\": \"descriptive|predictive|interventional|counterfactual\",\n  \"interventions\": [\n    {{\n      \"variable\": \"name_here\",\n      \"direction\": \"increase|decrease|set\",\n      \"magnitude\": \"small|medium|large|exact\"\n    }}\n  ],\n  \"targets\": [\"var_name_1\", \"var_name_2\", \"...\"]\n}}\n\"\"\"\n    return prompt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:11:47.013999Z","iopub.execute_input":"2025-12-04T05:11:47.014748Z","iopub.status.idle":"2025-12-04T05:11:47.022788Z","shell.execute_reply.started":"2025-12-04T05:11:47.014688Z","shell.execute_reply":"2025-12-04T05:11:47.021954Z"},"scrolled":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"prompt = make_query_interpret_prompt(USER_QUERY, schema)\n\n\n# ==== CALL MISTRAL TO INTERPRET QUERY ====\ndef call_mistral(prompt, max_new_tokens=512):\n    inputs = tokenizer(\n        [prompt],\n        return_tensors=\"pt\",\n    ).to(device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=False,\n            num_beams=1,\n        )\n\n    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return text\n\nraw_output = call_mistral(prompt)\nprint(\"Raw model output:\\n\", raw_output)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:21:01.277523Z","iopub.execute_input":"2025-12-04T05:21:01.277920Z","iopub.status.idle":"2025-12-04T05:21:17.501135Z","shell.execute_reply.started":"2025-12-04T05:21:01.277888Z","shell.execute_reply":"2025-12-04T05:21:17.500333Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Raw model output:\n You are a causal query interpreter.\n\nUser's question:\n\"\"\"How would the interaction have changed if the agent had apologized at the moment the customer first expressed frustration?\"\"\"\n\nYou are given a list of numeric variables you can intervene on or measure:\n\n- name: emo_sadness_mean\n  display_name: Sadness Mean\n  role: customer_emotion\n  description: Average intensity of sadness expressed by the customer throughout the call (scaled 0â€“1).\n\n- name: emo_sadness_median\n  display_name: Sadness Median\n  role: customer_emotion\n  description: Median sadness intensity across customer utterances (scaled 0â€“1).\n\n- name: emo_sadness_var\n  display_name: Sadness Variance\n  role: emotion_variability\n  description: Variance in sadness intensity across the call.\n\n- name: emo_sadness_max\n  display_name: Sadness Max\n  role: customer_emotion\n  description: Maximum sadness intensity reached during the call (scaled 0â€“1).\n\n- name: emo_approval_mean\n  display_name: Approval Mean\n  role: positive_emotion\n  description: Average approval or agreement expressed by the customer (scaled 0â€“1).\n\n- name: emo_approval_median\n  display_name: Approval Median\n  role: positive_emotion\n  description: Median approval intensity during the call (scaled 0â€“1).\n\n- name: emo_approval_var\n  display_name: Approval Variance\n  role: emotion_variability\n  description: Variability in approval intensity expressed across the call.\n\n- name: emo_approval_max\n  display_name: Approval Max\n  role: positive_emotion\n  description: Maximum approval intensity detected during the call (scaled 0â€“1).\n\n- name: emo_anger_mean\n  display_name: Anger Mean\n  role: customer_emotion\n  description: Average intensity of anger expressed by the customer (scaled 0â€“1).\n\n- name: emo_anger_median\n  display_name: Anger Median\n  role: customer_emotion\n  description: Median anger intensity across customer utterances (scaled 0â€“1).\n\n- name: emo_anger_var\n  display_name: Anger Variance\n  role: emotion_variability\n  description: Variance in anger intensity throughout the conversation.\n\n- name: emo_anger_max\n  display_name: Anger Max\n  role: customer_emotion\n  description: Maximum anger intensity reached at any point in the call (scaled 0â€“1).\n\n- name: emo_annoyance_mean\n  display_name: Annoyance Mean\n  role: customer_emotion\n  description: Average annoyance intensity expressed by the customer (scaled 0â€“1).\n\n- name: emo_annoyance_median\n  display_name: Annoyance Median\n  role: customer_emotion\n  description: Median annoyance intensity across customer utterances (scaled 0â€“1).\n\n- name: emo_annoyance_var\n  display_name: Annoyance Variance\n  role: emotion_variability\n  description: Variance in annoyance intensity over the call.\n\n- name: emo_annoyance_max\n  display_name: Annoyance Max\n  role: customer_emotion\n  description: Maximum annoyance level expressed by the customer (scaled 0â€“1).\n\n- name: emo_confusion_mean\n  display_name: Confusion Mean\n  role: customer_emotion\n  description: Average confusion expressed by the customer throughout the call (scaled 0â€“1).\n\n- name: emo_confusion_median\n  display_name: Confusion Median\n  role: customer_emotion\n  description: Median confusion level in the conversation (scaled 0â€“1).\n\n- name: emo_confusion_var\n  display_name: Confusion Variance\n  role: emotion_variability\n  description: Variance in confusion intensity across the call.\n\n- name: emo_confusion_max\n  display_name: Confusion Max\n  role: customer_emotion\n  description: Maximum confusion intensity recorded (scaled 0â€“1).\n\n- name: emo_gratitude_mean\n  display_name: Gratitude Mean\n  role: positive_emotion\n  description: Average gratitude expressed by the customer during the call.\n\n- name: emo_gratitude_median\n  display_name: Gratitude Median\n  role: positive_emotion\n  description: Median gratitude intensity across utterances (scaled 0â€“1).\n\n- name: emo_gratitude_var\n  display_name: Gratitude Variance\n  role: emotion_variability\n  description: Variance in gratitude intensity shown during the call.\n\n- name: emo_gratitude_max\n  display_name: Gratitude Max\n  role: positive_emotion\n  description: Maximum gratitude intensity observed during the call.\n\n- name: num_agent_turns\n  display_name: Number of Agent Turns\n  role: conversation_structure\n  description: How many times the agent spoke during the call.\n\n- name: num_customer_turns\n  display_name: Number of Customer Turns\n  role: conversation_structure\n  description: How many times the customer spoke during the call.\n\n- name: total_words_agent\n  display_name: Total Agent Words\n  role: conversation_volume\n  description: Total number of words spoken by the agent in the conversation.\n\n- name: total_words_customer\n  display_name: Total Customer Words\n  role: conversation_volume\n  description: Total number of words spoken by the customer in the conversation.\n\n- name: avg_agent_utt_len\n  display_name: Average Agent Utterance Length\n  role: conversation_style\n  description: Average number of words in each agent utterance.\n\n- name: avg_customer_utt_len\n  display_name: Average Customer Utterance Length\n  role: conversation_style\n  description: Average number of words in each customer utterance.\n\n- name: disfluency_count\n  display_name: Disfluency Count\n  role: speech_fluency\n  description: Number of speech disfluencies (um, uh, hesitations, repeated words).\n\n- name: question_count\n  display_name: Question Count\n  role: conversation_structure\n  description: Total number of questions asked during the call.\n\n- name: sentiment_start\n  display_name: Sentiment Start\n  role: sentiment\n  description: Sentiment score at the beginning of the call (negative to positive).\n\n- name: sentiment_end\n  display_name: Sentiment End\n  role: sentiment\n  description: Sentiment score at the end of the call.\n\n- name: sentiment_change\n  display_name: Sentiment Change\n  role: sentiment_dynamics\n  description: Change in sentiment from start to end (end âˆ’ start).\n\n\nYour job:\n1. Decide which variables the user implicitly wants to INTERVENE on (change), if any.\n2. Decide which variables should be the TARGET outcomes of interest.\n3. For each intervention, specify:\n   - \"variable\": one of the 'name' fields from the list above (use exact name)\n   - \"direction\": \"increase\", \"decrease\", or \"set\"\n   - \"magnitude\": \"small\", \"medium\", \"large\", or \"exact\"\n\n4. Classify the query_type as one of:\n   - \"descriptive\"      â†’ asking to describe or explain what is happening\n   - \"predictive\"       â†’ asking what will happen without changing anything\n   - \"interventional\"   â†’ asking about the effect of changing a variable in general\n   - \"counterfactual\"   â†’ asking what would have happened in this specific call if something had been different\n\nIf the user is only asking for an explanation of what is happening (no change), then:\n- query_type should be \"descriptive\"\n- \"interventions\" should be an empty list []\n- \"targets\" should list the most relevant variables to describe.\n\nImportant rules:\n- Use ONLY variable names from the provided list for \"variable\" and in \"targets\".\n- Do NOT invent new variable names.\n- If no clear intervention is implied, leave \"interventions\": [].\n- Always output valid JSON.\n\nOutput STRICTLY in this JSON format and nothing else:\n\n{\n  \"query_type\": \"descriptive|predictive|interventional|counterfactual\",\n  \"interventions\": [\n    {\n      \"variable\": \"name_here\",\n      \"direction\": \"increase|decrease|set\",\n      \"magnitude\": \"small|medium|large|exact\"\n    }\n  ],\n  \"targets\": [\"var_name_1\", \"var_name_2\", \"...\"]\n}\n\nExample:\n\n{\n  \"query_type\": \"interventional\",\n  \"interventions\": [\n    {\n      \"variable\": \"emo_anger_mean\",\n      \"direction\": \"decrease\",\n      \"magnitude\": \"medium\"\n    }\n  ],\n  \"targets\": [\"emo_anger_max\", \"emo_anger_median\", \"num_customer_turns\"]\n}\n\n\nAnswer:\n\n{\n  \"query_type\": \"counterfactual\",\n  \"interventions\": [\n    {\n      \"variable\": \"emo_sadness_mean\",\n      \"direction\": \"set\",\n      \"magnitude\": \"exact\"\n    },\n    {\n      \"variable\": \"emo_anger_mean\",\n      \"direction\": \"decrease\",\n      \"magnitude\": \"medium\"\n    }\n  ],\n  \"targets\": [\"emo_sadness_mean\", \"emo_sadness_median\", \"emo_anger_mean\", \"emo_anger_median\", \"num_customer_turns\"]\n}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ==== EXTRACT JSON FROM MODEL OUTPUT ====\nimport re\n\nimport json\n\ndef extract_plan_from_output(raw_output: str):\n    \"\"\"\n    Extract the single JSON plan object from the model output.\n    We:\n      1) Take only the part after the last 'Answer:' marker.\n      2) Find the first '{' and the last '}' in that segment.\n      3) Parse that as JSON.\n    \"\"\"\n    segment = raw_output\n\n    # 1. Keep only text after the LAST \"Answer:\"\n    if \"Answer:\" in segment:\n        segment = segment.split(\"Answer:\")[-1]\n\n    # 2. Find JSON boundaries\n    start = segment.find(\"{\")\n    end = segment.rfind(\"}\")\n\n    if start == -1 or end == -1 or end <= start:\n        raise ValueError(\"Could not find a JSON object in model output.\")\n\n    json_str = segment[start:end+1]\n\n    # 3. Clean potential smart quotes (just in case)\n    json_str = (json_str.replace(\"â€œ\", '\"')\n                         .replace(\"â€\", '\"')\n                         .replace(\"â€˜\", '\"')\n                         .replace(\"â€™\", '\"'))\n\n    # 4. Parse JSON\n    plan = json.loads(json_str)\n    return plan\n\nplan = extract_plan_from_output(raw_output)\nprint(\"\\nParsed plan:\\n\", plan)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:27:48.884463Z","iopub.execute_input":"2025-12-04T05:27:48.884774Z","iopub.status.idle":"2025-12-04T05:27:48.891483Z","shell.execute_reply.started":"2025-12-04T05:27:48.884750Z","shell.execute_reply":"2025-12-04T05:27:48.890688Z"}},"outputs":[{"name":"stdout","text":"\nParsed plan:\n {'query_type': 'counterfactual', 'interventions': [{'variable': 'emo_sadness_mean', 'direction': 'set', 'magnitude': 'exact'}, {'variable': 'emo_anger_mean', 'direction': 'decrease', 'magnitude': 'medium'}], 'targets': ['emo_sadness_mean', 'emo_sadness_median', 'emo_anger_mean', 'emo_anger_median', 'num_customer_turns']}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ==== MAP MAGNITUDE TO NUMERIC VALUE ====\ndef magnitude_to_new_value(current_val, var_meta, magnitude, direction, df):\n    \"\"\"\n    Convert (direction, magnitude) into a numeric value for intervention.\n    Uses variable's scale_min/scale_max and/or dataset stats.\n    \"\"\"\n    name = var_meta[\"name\"]\n    vmin = var_meta.get(\"scale_min\", float(df[name].min()))\n    vmax = var_meta.get(\"scale_max\", float(df[name].max()))\n    span = vmax - vmin if vmax > vmin else 1.0\n\n    # If direction is \"set\", we choose an absolute target value.\n    if direction == \"set\":\n        if magnitude == \"exact\":\n            # Use dataset median as a neutral \"exact\" target\n            base = float(df[name].median())\n        elif magnitude == \"small\":\n            base = vmin + 0.25 * span\n        elif magnitude == \"medium\":\n            base = vmin + 0.50 * span\n        elif magnitude == \"large\":\n            base = vmin + 0.75 * span\n        else:\n            base = float(df[name].mean())\n        return float(np.clip(base, vmin, vmax))\n\n    # For increase / decrease, we use a step around the current value\n    if magnitude == \"small\":\n        step = 0.15 * span\n    elif magnitude == \"medium\":\n        step = 0.30 * span\n    elif magnitude == \"large\":\n        step = 0.50 * span\n        step = min(step, span)  # clamp\n    else:\n        step = 0.20 * span\n\n    if direction == \"decrease\":\n        step = -step\n\n    new_val = current_val + step\n    return float(np.clip(new_val, vmin, vmax))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:31:10.965296Z","iopub.execute_input":"2025-12-04T05:31:10.965586Z","iopub.status.idle":"2025-12-04T05:31:10.972231Z","shell.execute_reply.started":"2025-12-04T05:31:10.965564Z","shell.execute_reply":"2025-12-04T05:31:10.971579Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# ========================\n# RUN SCM FOR SELECTED TRANSCRIPTS\n# ========================\nresults_for_llm = []   # list of dicts, one per transcript\n\ninterventions_spec = plan.get(\"interventions\", [])\ntarget_vars = plan.get(\"targets\", [])\n\nfor tid in TEST_TRANSCRIPT_IDS:\n    # find row for this transcript\n    matches = df_full[df_full[\"transcript_id\"] == tid]\n    if matches.empty:\n        print(f\"WARNING: transcript_id {tid} not found in dataset.\")\n        continue\n\n    base_full = matches.iloc[0]\n    base_numeric = base_full[NUMERIC_VARS]\n\n    interventions_numeric = {}\n\n    for inter in interventions_spec:\n        var = inter[\"variable\"]\n        direction = inter.get(\"direction\", \"increase\")\n        magnitude = inter.get(\"magnitude\", \"small\")\n\n        if var not in NUMERIC_VARS:\n            print(f\"WARNING: intervention var {var} not a known numeric variable. Skipping.\")\n            continue\n\n        var_meta = schema_by_name[var]\n        cur_val = float(base_numeric[var])\n\n        new_val = magnitude_to_new_value(cur_val, var_meta, magnitude, direction, df_numeric)\n        interventions_numeric[var] = new_val\n\n    if not interventions_numeric:\n        print(f\"No valid interventions for transcript_id {tid}. Skipping SCM.\")\n        continue\n\n    # simulate SCM\n    cf_numeric = simulate_scm(base_numeric, interventions_numeric, bundle)\n\n    # collect before/after for targets\n    target_summaries = []\n    for tvar in target_vars:\n        if tvar not in NUMERIC_VARS:\n            print(f\"WARNING: target var {tvar} not numeric. Skipping.\")\n            continue\n        before = float(base_numeric[tvar])\n        after = float(cf_numeric[tvar])\n        target_summaries.append({\n            \"variable\": tvar,\n            \"before\": before,\n            \"after\": after,\n            \"delta\": after - before,\n        })\n\n    results_for_llm.append({\n        \"transcript_id\": tid,\n        \"query_type\": plan.get(\"query_type\", \"counterfactual\"),\n        \"interventions\": interventions_numeric,\n        \"targets\": target_summaries,\n    })\n\n# ========================\n# SHOW RESULT SUMMARY\n# ========================\nprint(\"\\n--- SCM RESULTS FOR LLM ---\\n\")\nfor item in results_for_llm:\n    print(f\"Transcript: {item['transcript_id']}\")\n    print(\"Interventions (numeric):\")\n    for k, v in item[\"interventions\"].items():\n        print(f\"  - {k}: {v}\")\n    print(\"Targets (before â†’ after, Î”):\")\n    for t in item[\"targets\"]:\n        print(f\"  - {t['variable']}: {t['before']:.4f} â†’ {t['after']:.4f} (Î” = {t['delta']:.4f})\")\n    print()\n\n# Save for downstream LLM\nOUTPUT_JSON_PATH = \"/kaggle/working/scm_results_for_llm.json\"\nwith open(OUTPUT_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n    json.dump(results_for_llm, f, indent=4, ensure_ascii=False)\n\nprint(\"Saved SCM results for LLM to:\", OUTPUT_JSON_PATH)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T05:31:15.266878Z","iopub.execute_input":"2025-12-04T05:31:15.267132Z","iopub.status.idle":"2025-12-04T05:31:15.488534Z","shell.execute_reply.started":"2025-12-04T05:31:15.267115Z","shell.execute_reply":"2025-12-04T05:31:15.487918Z"}},"outputs":[{"name":"stdout","text":"\n--- SCM RESULTS FOR LLM ---\n\nTranscript: 1c99b47c-4e80-49d5-b3c6-52b0c3230fa8\nInterventions (numeric):\n  - emo_sadness_mean: 0.0106707176353127\n  - emo_anger_mean: 0.0008982101895857\nTargets (before â†’ after, Î”):\n  - emo_sadness_mean: 0.0075 â†’ 0.0107 (Î” = 0.0032)\n  - emo_sadness_median: 0.0020 â†’ 0.0015 (Î” = -0.0005)\n  - emo_anger_mean: 0.0104 â†’ 0.0009 (Î” = -0.0095)\n  - emo_anger_median: 0.0025 â†’ 0.0013 (Î” = -0.0012)\n  - num_customer_turns: 14.0000 â†’ 17.0033 (Î” = 3.0033)\n\nSaved SCM results for LLM to: /kaggle/working/scm_results_for_llm.json\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}